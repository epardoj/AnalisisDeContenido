{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02489050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_md')\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Doc, Span\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import string\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.language import Language\n",
    "import re\n",
    "import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from time import time\n",
    "import subprocess\n",
    "import gc\n",
    "for limpio in range(3):\n",
    "    gc.collect(generation=limpio)\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import unicodedata\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "for limpio in range(3):\n",
    "        gc.collect(generation=limpio)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "couch = couchdb.Server('')#colocar la dirección de couchDB en el equipo\n",
    "dbname = \"testimonios\"\n",
    "if dbname in couch:\n",
    "    db = couch[dbname]\n",
    "else:\n",
    "    db = couch.create(dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "otros = ['RJN', 'FAFZ']\n",
    "sujeto =['CJB', 'RAR', 'PAR', 'RCL', 'JVR', 'CLWP']\n",
    "sobreviviente = ['CJB', 'RAR', 'PAR']\n",
    "desaparecido = ['RCL', 'JVR', 'CLWP']\n",
    "etapa = ['infancia', 'adolescencia', 'toma_de_decision', 'vida_militar', 'hecho_victimizante',   \n",
    "         'despues_hecho_victimizante', 'familia',]\n",
    "antes = ['infancia', 'adolescencia', 'toma_de_decision']\n",
    "durante = ['vida_militar','hecho_victimizante']\n",
    "despues = ['despues_hecho_victimizante']\n",
    "familia = ['familia']\n",
    "lista_color = ['#0000FF', '#008000', '#FF0000', '#00BFBF', '#BF00BF', '#BFBF00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83421b",
   "metadata": {},
   "source": [
    "## Análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempo = 0\n",
    "largo = 0\n",
    "sujetos = []\n",
    "etapa_rel = []\n",
    "tiempos = []\n",
    "extension = []\n",
    "for i in sujeto:\n",
    "    for j in etapa:\n",
    "        for id in db:\n",
    "            doc = db.get(id)\n",
    "            if doc['nombre'] == i and doc['etapa'] == j:\n",
    "                tiempo+= int(round(float(doc['duracion']), 0))\n",
    "                largo+= int(len(doc['relato']))\n",
    "        sujetos.append(i)\n",
    "        etapa_rel.append(j)\n",
    "        tiempos.append(tiempo)\n",
    "        extension.append(largo)\n",
    "        tiempo = 0\n",
    "        largo = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptivos = pd.DataFrame(zip(sujetos, etapa_rel, tiempos, extension), \n",
    "                            columns=['sujeto', 'etapa', 'tiempo_audio', 'ext_texto'])\n",
    "descriptivos.to_excel('descriptivos.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a619ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptivos = pd.read_excel('descriptivos.xlsx')\n",
    "df2 = descriptivos[['sujeto', 'tiempo_audio', 'ext_texto']]\n",
    "resumen = df2.groupby(['sujeto'], as_index=False).sum()\n",
    "fig, ax = plt.subplots(1, 2, sharex = True, figsize=(15,10))\n",
    "fig.suptitle('Distribución de datos por sujeto', fontsize = 20)\n",
    "ax[0].set_title('Proporción de audios (tiempo)', fontsize = 16)\n",
    "ax[0].pie(resumen.tiempo_audio, labels=resumen.sujeto, autopct='%1.2f%%', shadow = True,\n",
    "          colors=lista_color, counterclock = False, explode = (0, 0, 0, 0, 0.1, 0), textprops={\"fontsize\":14})\n",
    "#ax[0].axis(\"equal\")\n",
    "ax[1].set_title('Proporción de textos (palabras)', fontsize = 16)\n",
    "ax[1].pie(resumen.ext_texto, labels=resumen.sujeto, autopct='%1.2f%%', shadow = True,\n",
    "          colors=lista_color, counterclock = False, explode = (0, 0, 0, 0, 0.1, 0), textprops={\"fontsize\":14})\n",
    "#ax[1].axis(\"equal\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91196797",
   "metadata": {},
   "outputs": [],
   "source": [
    "posicion = 0\n",
    "fig, ax = plt.subplots(2, 3, sharex = True, figsize=(15,10))\n",
    "fig.suptitle('Tiempo de grabaciones por etapa', fontsize = 16)\n",
    "for a in range(0, 2):\n",
    "    for b in range(0, 3):\n",
    "        df_filtrado = descriptivos[descriptivos['sujeto']==sujeto[posicion]]\n",
    "        ax[a,b].set_title(sujeto[posicion], fontsize = 14, color = lista_color[posicion])\n",
    "        ax[a,b].bar(df_filtrado.etapa, df_filtrado.tiempo_audio, color = lista_color[posicion])\n",
    "        ax[a,b].tick_params(axis=\"x\", labelrotation=75)\n",
    "        textotal = str(round(df_filtrado['tiempo_audio'].sum()/3600,2)) + ' \\nhoras'\n",
    "        ax[a,b].text(1, max(df_filtrado['tiempo_audio']-(max(df_filtrado['tiempo_audio']*0.1))),\n",
    "                              textotal, fontsize = 14)\n",
    "        if a == 0 and b == 0:\n",
    "            ax[0,0].set_ylabel('Sobrevivientes \\n tiempo (segundos)')\n",
    "        elif a == 1 and b == 0:\n",
    "            ax[1,0].set_ylabel('Desaparecidos \\n tiempo (segundos)')\n",
    "        else:\n",
    "            ax[a,b].set_ylabel('tiempo (segundos)')\n",
    "        posicion += 1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "posicion = 0\n",
    "fig, ax = plt.subplots(2, 3, sharex = True, figsize=(15,10))\n",
    "fig.suptitle('Cantidad de palabras por etapa', fontsize = 16)\n",
    "for a in range(0, 2):\n",
    "    for b in range(0, 3):\n",
    "        df_filtrado = descriptivos[descriptivos['sujeto']==sujeto[posicion]]\n",
    "        ax[a,b].set_title(sujeto[posicion], fontsize = 14, color = lista_color[posicion])\n",
    "        ax[a,b].bar(df_filtrado.etapa, df_filtrado.ext_texto, color = lista_color[posicion])\n",
    "        ax[a,b].tick_params(axis=\"x\", labelrotation=75)\n",
    "        textotal = str(df_filtrado['ext_texto'].sum()) + ' \\npalabras'\n",
    "        ax[a,b].text(1, max(df_filtrado['ext_texto']-(max(df_filtrado['ext_texto']*0.1))),\n",
    "                              textotal, fontsize = 14)\n",
    "        if a == 0 and b == 0:\n",
    "            ax[0,0].set_ylabel('Sobrevivientes \\n Cantidad')\n",
    "        elif a == 1 and b == 0:\n",
    "            ax[1,0].set_ylabel('Desaparecidos \\n Cantidad')\n",
    "        else:\n",
    "            ax[a,b].set_ylabel('Cantidad')\n",
    "        posicion += 1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97347df7",
   "metadata": {},
   "source": [
    "### Limpieza y tokenización de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddfbfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(documento):\n",
    "    texto = unidecode.unidecode(documento)\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8', 'ignore') \n",
    "    texto = texto.replace(\"\\t\", \" \")\n",
    "    texto = re.sub(\"\\d+\", ' ', texto) #quitar decimales\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    texto = re.sub(regex, \"\", texto)\n",
    "    documento = nlp(texto)\n",
    "    tokens_limpios = [token.lemma_.lower() for token in documento if token.pos_ != \"PROPN\"]\n",
    "    tokens_limpios = [token for token in tokens_limpios if not nlp(token)[0].is_punct | nlp(token)[0].is_stop]\n",
    "    tokens_limpios = [token for token in tokens_limpios if token != \" \"]\n",
    "    tokens_limpios = [token for token in tokens_limpios if len(token) > 3]\n",
    "    return tokens_limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22db536",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in db:\n",
    "    doc = db.get(id)\n",
    "    if doc['nombre'] in otros:\n",
    "        %time doc['tokens'] = limpieza(doc['relato'])\n",
    "    db.save(doc)\n",
    "    for limpio in range(3):\n",
    "        gc.collect(generation=limpio)\n",
    "subprocess.run('shutdown -h 2', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd4fd3",
   "metadata": {},
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc98e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracciontokens(lista_sujetos, etapa):\n",
    "    \"\"\"\n",
    "    función que permite unificar las listas de tokens de las distintas etápas transcritas en el marco de la investigación.\n",
    "    Para que el proceso funcione, se requiere que esté conectado a couchDB.\n",
    "    La función requiere dos valores:\n",
    "    \n",
    "    1. lista_sujetos = lista de las siglas de nombres de los tokens a extraer.\n",
    "    2. etapa = corresponde a la lista de las etápas que se van a analizar. \n",
    "    \n",
    "    El retorno de la función es una lista donde estarían todos los tokens del sujeto con base en la etapa \n",
    "    elegida (antes, durante, después o familia). \n",
    "    \"\"\"\n",
    "    palabras = []\n",
    "    lista_tokens = []\n",
    "    for id in db:\n",
    "        doc = db.get(id)\n",
    "        if doc['nombre'] in lista_sujetos:\n",
    "            if doc['etapa'] in etapa:\n",
    "                lista = doc['tokens']\n",
    "                lista = [i for i in lista if i != \" \"]\n",
    "                palabras.append(lista)\n",
    "    return palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "bolsa = extracciontokens(sujeto, etapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def armado_corpus(lista_tokens, tipo_modelo = 'token'):\n",
    "    \"\"\"\n",
    "    La función crea los modelos por token (por defecto), bigramas o trigramas.\n",
    "    Los datos que requiere son:\n",
    "    lista_tokens = listado de palabras preprocesadas para realizar el modelo.\n",
    "    tipo_modelo = se debe escribir 'token' en caso de modelar por unigrama, 'bigram' para modelas bigramas y 'trigram'\n",
    "    para modelar trigramas. Por defecto modela por unigramas.\n",
    "    \"\"\"\n",
    "    if tipo_modelo == 'bigram':\n",
    "        bigram = gensim.models.Phrases(bolsa, min_count=5, threshold= 100)\n",
    "        bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "        bolsa_mod = [bigram_mod[doc] for doc in lista_tokens]\n",
    "        diccionario = corpora.Dictionary(bolsa_mod)\n",
    "        diccionario.filter_extremes(no_below = 2, no_above = 0.8)\n",
    "        corpus = [diccionario.doc2bow(i) for i in lista_tokens]\n",
    "    elif tipo_modelo == 'trigram':\n",
    "        bigram = gensim.models.Phrases(bolsa, min_count=5, threshold= 100)\n",
    "        trigram = gensim.models.Phrases(bigram[bolsa], threshold=100)\n",
    "        trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "        bolsa_mod = [trigram_mod[doc] for doc in lista_tokens]\n",
    "        diccionario = corpora.Dictionary(bolsa_mod)\n",
    "        diccionario.filter_extremes(no_below = 2, no_above = 0.8)\n",
    "        corpus = [diccionario.doc2bow(i) for i in lista_tokens]\n",
    "    elif tipo_modelo == 'token':\n",
    "        bolsa_mod = lista_tokens\n",
    "        diccionario = corpora.Dictionary(lista_tokens)\n",
    "        diccionario.filter_extremes(no_below = 2, no_above = 0.8)\n",
    "        corpus = [diccionario.doc2bow(i) for i in lista_tokens]\n",
    "    return diccionario, corpus, bolsa_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario, corpus, bolsa = armado_corpus(bolsa, 'token')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0796d5f",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df928a",
   "metadata": {},
   "source": [
    "## 16 documentos (20%) por pase con 20 pases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicos = []\n",
    "coherencia = []\n",
    "modelo = []\n",
    "for topico in range(2, 10):\n",
    "    \n",
    "    modelo_lda = models.LdaModel(corpus=corpus, id2word=diccionario, num_topics= topico, random_state=100, \n",
    "                                 update_every=1, chunksize=16,passes=20, alpha='auto')\n",
    "    modelo.append(modelo_lda)\n",
    "    coherencia_modelo_lda = CoherenceModel(model = modelo_lda, texts= bolsa, dictionary=diccionario,\n",
    "                                      coherence='c_v')\n",
    "    coherencia.append(coherencia_modelo_lda.get_coherence())\n",
    "    topicos.append(topico)\n",
    "\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "plt.plot(topicos, coherencia)\n",
    "plt.xticks(range(2, max(topicos)+1))\n",
    "plt.xlabel('cantidad de tópicos')\n",
    "plt.ylabel('coherencia')\n",
    "plt.title('Estimación de la cantidad de tópicos')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9973a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimacion1 = pd.DataFrame(zip(['Modelo 1', 'Modelo 2', 'Modelo 3', 'Modelo 4', 'Modelo 5', 'Modelo 6'], topicos, coherencia), columns = ['Modelo entrenado', 'Cant. tópicos', 'Coherencia'])\n",
    "estimacion1.to_excel('tabla_estimacion_1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0165c",
   "metadata": {},
   "source": [
    "### Visualización modelo de 7 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948ca82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis3 = pyLDAvis.gensim.prepare(modelo[5], corpus, diccionario) \n",
    "vis3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32f50a",
   "metadata": {},
   "source": [
    "### Visualización modelo de 6 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis2 = pyLDAvis.gensim.prepare(modelo[4], corpus, diccionario) \n",
    "vis2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178d608",
   "metadata": {},
   "source": [
    "### Visualización modelo de 5 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(modelo[3], corpus, diccionario) \n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd85e21",
   "metadata": {},
   "source": [
    "## 20 documentos (25%) por pase con 30 pases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicosb = []\n",
    "coherenciab = []\n",
    "modelob = []\n",
    "for topico in range(2, 10):\n",
    "    \n",
    "    modelo_lda = models.LdaModel(corpus=corpus, id2word=diccionario, num_topics= topico, random_state=100, \n",
    "                                 update_every=1, chunksize=20,passes=30, alpha='auto')\n",
    "    modelob.append(modelo_lda)\n",
    "    coherencia_modelo_lda = CoherenceModel(model = modelo_lda, texts= bolsa, dictionary=diccionario,\n",
    "                                      coherence='c_v')\n",
    "    coherenciab.append(coherencia_modelo_lda.get_coherence())\n",
    "    topicosb.append(topico)\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "#figure(figsize=(40/2.54, 10/2.54))\n",
    "plt.plot(topicosb, coherenciab)\n",
    "plt.xticks(range(2, max(topicosb)+1))\n",
    "plt.xlabel('cantidad de tópicos')\n",
    "plt.ylabel('coherencia')\n",
    "plt.title('Estimación de la cantidad de tópicos')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daed06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimacion2 = pd.DataFrame(zip(['Modelo 1', 'Modelo 2', 'Modelo 3', 'Modelo 4', 'Modelo 5', 'Modelo 6'], topicosb, coherenciab), columns = ['Modelo entrenado', 'Cant. tópicos', 'Coherencia'])\n",
    "estimacion2.to_excel('tabla_estimacion_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31119dc",
   "metadata": {},
   "source": [
    "### Visualización modelo de 7 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis6 = pyLDAvis.gensim.prepare(modelob[5], corpus, diccionario) \n",
    "vis6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4d58f",
   "metadata": {},
   "source": [
    "### Visualización modelo de 6 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis5 = pyLDAvis.gensim.prepare(modelob[4], corpus, diccionario) \n",
    "vis5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683594d",
   "metadata": {},
   "source": [
    "### Visualización modelo de 5 tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477875fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis4 = pyLDAvis.gensim.prepare(modelob[3], corpus, diccionario) \n",
    "vis4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29eae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicos = []\n",
    "for indice, topic in modelo[3].print_topics(num_words=20):\n",
    "    topico = topic.split(' + ')\n",
    "    topicos.append(topico)\n",
    "basetopicos = pd.DataFrame(topicos)\n",
    "basetopicos = basetopicos.transpose()\n",
    "basetopicos.columns = ['Topico_1', 'Topico_2', 'Topico_3', 'Topico_4', 'Topico_5']\n",
    "columnas = list(basetopicos.columns)\n",
    "for i in columnas:\n",
    "    listatopic = basetopicos[i].str.split('*', expand=True)\n",
    "    listatopic.columns = ['%_' + i.lower(), i.lower()]\n",
    "    basetopicos = pd.concat([basetopicos, listatopic], axis = 1)\n",
    "basetopicos = basetopicos.drop(columnas, axis=1)\n",
    "basetopicos.to_excel('base_topicos_modelo_A.xlsx')\n",
    "basetopicos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b01282",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicos = []\n",
    "for indice, topic in modelob[3].print_topics(num_words=20):\n",
    "    topico = topic.split(' + ')\n",
    "    topicos.append(topico)\n",
    "basetopicos = pd.DataFrame(topicos)\n",
    "basetopicos = basetopicos.transpose()\n",
    "basetopicos.columns = ['Topico_1', 'Topico_2', 'Topico_3', 'Topico_4', 'Topico_5']\n",
    "columnas = list(basetopicos.columns)\n",
    "for i in columnas:\n",
    "    listatopic = basetopicos[i].str.split('*', expand=True)\n",
    "    listatopic.columns = ['%_' + i.lower(), i.lower()]\n",
    "    basetopicos = pd.concat([basetopicos, listatopic], axis = 1)\n",
    "basetopicos = basetopicos.drop(columnas, axis=1)\n",
    "basetopicos.to_excel('base_topicos_modelo_B.xlsx')\n",
    "basetopicos.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6398c55",
   "metadata": {},
   "source": [
    "# Tópicos presentes en los textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b605baf",
   "metadata": {},
   "source": [
    "## Sobrevivientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3005b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=modelob[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos antes del hecho victimizante')\n",
    "colores = lista_color[0:3]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = sobreviviente[s]\n",
    "    relato1 = extracciontokens(dato_sujeto, antes)\n",
    "    diccionario1, corpus1, bolsa1 = armado_corpus(relato1)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    lista_topicos = ['Hecho vict.', 'Infancia', 'Después hech.', 'Proyecto vida', 'Vida mil.']\n",
    "    for topico in lda[corpus1]:\n",
    "        for i in range(0, len(topico)):\n",
    "            dist_indices.append(topico[i][0])\n",
    "            dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "            dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_antes_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b10900",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos durante del hecho victimizante')\n",
    "colores = lista_color[0:3]\n",
    "lista_topicos = ['Hecho vict.', 'Infancia', 'Después hech.', 'Proyecto vida', 'Vida mil.']\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = sobreviviente[s]\n",
    "    relato2 = extracciontokens(dato_sujeto, durante)\n",
    "    diccionario2, corpus2, bolsa2 = armado_corpus(relato2)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus2]:\n",
    "        for i in range(0, len(topico)):\n",
    "            dist_indices.append(topico[i][0])\n",
    "            dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "            dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_durante_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86434f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos después del hecho victimizante')\n",
    "colores = lista_color[0:3]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = sobreviviente[s]\n",
    "    relato3 = extracciontokens(dato_sujeto, despues)\n",
    "    diccionario3, corpus3, bolsa3 = armado_corpus(relato3)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus3]:\n",
    "        for i in range(0, len(topico)):\n",
    "            dist_indices.append(topico[i][0])\n",
    "            dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "            dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_despues_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos de familiares de sujetos sobrevivientes')\n",
    "colores = lista_color[0:3]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = sobreviviente[s]\n",
    "    relato4 = extracciontokens(dato_sujeto, familia)\n",
    "    diccionario4, corpus4, bolsa4 = armado_corpus(relato4)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus4]:\n",
    "        for i in range(0, len(topico)):\n",
    "            dist_indices.append(topico[i][0])\n",
    "            dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "            dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_familia_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9767be",
   "metadata": {},
   "source": [
    "### Desaparecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ae2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos antes del hecho victimizante')\n",
    "colores = lista_color[3:6]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = desaparecido[s]\n",
    "    relato5 = extracciontokens(dato_sujeto, antes)\n",
    "    diccionario5, corpus5, bolsa5 = armado_corpus(relato5)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus5]:\n",
    "        for i in range(0, len(topico)):\n",
    "            dist_indices.append(topico[i][0])\n",
    "            dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "            dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_antes_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos durante del hecho victimizante')\n",
    "colores = lista_color[3:6]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = desaparecido[s]\n",
    "    relato6 = extracciontokens(dato_sujeto, durante)\n",
    "    diccionario6, corpus6, bolsa6 = armado_corpus(relato6)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus6]:\n",
    "        for i in range(0, len(topico)):\n",
    "            dist_indices.append(topico[i][0])\n",
    "            dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "            dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_durante_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos despues del hecho victimizante')\n",
    "colores = lista_color[3:6]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = desaparecido[s]\n",
    "    relato7 = extracciontokens(dato_sujeto, despues)\n",
    "    diccionario7, corpus7, bolsa7 = armado_corpus(relato7)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus7]:\n",
    "        for i in range(0, len(topico)):\n",
    "            if type(topico) is tuple:\n",
    "                dist_indices.append(topico[0])\n",
    "                dist_topicos.append(lista_topicos[topico[0]])\n",
    "                dist_contrib.append(topico[1])\n",
    "            else:\n",
    "                dist_indices.append(topico[i][0])\n",
    "                dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "                dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), \n",
    "                                        columns=['# de Topico', 'Topico', 'Contribucion'])   \n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_despues_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,8))\n",
    "fig.suptitle('Tópicos más importantes en los relatos de familiares')\n",
    "colores = lista_color[3:6]\n",
    "for s in range(0,3):\n",
    "    dato_sujeto = desaparecido[s]\n",
    "    relato8 = extracciontokens(dato_sujeto, familia)\n",
    "    diccionario8, corpus8, bolsa8 = armado_corpus(relato8)\n",
    "    dist_indices = []\n",
    "    dist_topicos = []\n",
    "    dist_contrib = []\n",
    "    for topico in lda[corpus8]:\n",
    "        for i in range(0, len(topico)):\n",
    "            if type(topico) is tuple:\n",
    "                dist_indices.append(topico[0])\n",
    "                dist_topicos.append(lista_topicos[topico[0]])\n",
    "                dist_contrib.append(topico[1])\n",
    "            else:\n",
    "                dist_indices.append(topico[i][0])\n",
    "                dist_topicos.append(lista_topicos[topico[i][0]])\n",
    "                dist_contrib.append(topico[i][1])\n",
    "    distribucion_topicos = pd.DataFrame(list(zip(dist_indices, dist_topicos, dist_contrib)), columns=['# de Topico', 'Topico', 'Contribucion'])\n",
    "    distribucion_topicos = distribucion_topicos.groupby(by='Topico', as_index=False).mean()\n",
    "    distribucion_topicos.sort_values('Contribucion', ascending=False, inplace=True)\n",
    "    distribucion_topicos.to_excel('distribucion_topicos_familia_'+ dato_sujeto + '.xlsx')\n",
    "    color = colores[s]\n",
    "    ax[s].bar(distribucion_topicos.Topico, distribucion_topicos.Contribucion, color = color)\n",
    "    ax[s].set_title(str(dato_sujeto))\n",
    "    for a in ax.flat:\n",
    "        a.set(xlabel='Tópicos', ylabel='Contribución(promedio)')\n",
    "    fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
